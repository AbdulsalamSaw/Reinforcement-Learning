{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68b8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dca2cdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | :\u001b[43m \u001b[0m: |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d905428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(env, epochs, q_table):\n",
    "\n",
    "\n",
    "    #0.01 seems to be the best fit for our RL game it gave back the best results\n",
    "    learning_rate = 0.1\n",
    "    #0.5 discount factor seems the fair amount for a test run\n",
    "    discount_factor = 0.5\n",
    "    #0.5 exploration gave back the best results; the higher it goes, the more risk the agent takes\n",
    "    exploration = 0.1\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for episode in range(epochs):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        total_steps = 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if np.random.uniform(0, 1) < exploration:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * (\n",
    "                        reward + discount_factor * np.max(q_table[next_state, :]))\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            total_steps += 1\n",
    "\n",
    "        results.append([episode, total_reward, total_steps])\n",
    "\n",
    "    return results, q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a294e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78024aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "observation_space_size = env.observation_space.n\n",
    "action_space_size = env.action_space.n\n",
    "q_table = np.zeros((observation_space_size, action_space_size))  # Initialize Q-table\n",
    "\n",
    "epochs = 1001\n",
    "results, q_table = train_and_evaluate(env, epochs, q_table)\n",
    "df = pd.DataFrame(results, columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "\n",
    "dfs.append(df)\n",
    "\n",
    "# Update Q-table with the results from 1000 epochs\n",
    "q_table_1000 = np.copy(q_table)\n",
    "\n",
    "epochs = 5001\n",
    "results, q_table_5000 = train_and_evaluate(env, epochs, q_table_1000)\n",
    "df = pd.DataFrame(results, columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "\n",
    "dfs.append(df)\n",
    "\n",
    "# Update Q-table with the results from 5000 epochs\n",
    "q_table_5000 = np.copy(q_table_5000)\n",
    "\n",
    "epochs = 10001\n",
    "results, q_table_10000 = train_and_evaluate(env, epochs, q_table_5000)\n",
    "df = pd.DataFrame(results, columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "dfs.append(df)\n",
    "q_table=q_table_10000\n",
    "    \n",
    "    \n",
    "df_1000_epochs = dfs[0]\n",
    "df_5000_epochs = dfs[1]\n",
    "df_10000_epochs = dfs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff44b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Reward  Steps\n",
      "     0    -578    200\n",
      " Epoch  Reward  Steps\n",
      "   100    -254    200\n",
      " Epoch  Reward  Steps\n",
      "   200    -202    169\n",
      " Epoch  Reward  Steps\n",
      "   300    -120    105\n",
      " Epoch  Reward  Steps\n",
      "   400     -54     66\n",
      " Epoch  Reward  Steps\n",
      "   500     -83     77\n",
      " Epoch  Reward  Steps\n",
      "   600    -245    200\n",
      " Epoch  Reward  Steps\n",
      "   700    -122    116\n",
      " Epoch  Reward  Steps\n",
      "   800    -113     89\n",
      " Epoch  Reward  Steps\n",
      "   900    -191    158\n",
      " Epoch  Reward  Steps\n",
      "  1000       0     21\n"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(df_1000_epochs), 100):\n",
    "    row = df_1000_epochs.iloc[index]\n",
    "    data = pd.DataFrame([row], columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "    print(data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e0266b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Reward  Steps\n",
      "     0     -65     50\n",
      " Epoch  Reward  Steps\n",
      "   500     -81     75\n",
      " Epoch  Reward  Steps\n",
      "  1000     -24     45\n",
      " Epoch  Reward  Steps\n",
      "  1500      -1     22\n",
      " Epoch  Reward  Steps\n",
      "  2000      -4     16\n",
      " Epoch  Reward  Steps\n",
      "  2500       8     13\n",
      " Epoch  Reward  Steps\n",
      "  3000      -3     24\n",
      " Epoch  Reward  Steps\n",
      "  3500     -22     25\n",
      " Epoch  Reward  Steps\n",
      "  4000       0     21\n",
      " Epoch  Reward  Steps\n",
      "  4500      11     10\n",
      " Epoch  Reward  Steps\n",
      "  5000      -4     16\n"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(df_5000_epochs), 500):\n",
    "    row = df_5000_epochs.iloc[index]\n",
    "    data = pd.DataFrame([row], columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "    print(data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3562bff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  Reward  Steps\n",
      "     0      -1     22\n",
      " Epoch  Reward  Steps\n",
      "  1000       8     13\n",
      " Epoch  Reward  Steps\n",
      "  2000       6     15\n",
      " Epoch  Reward  Steps\n",
      "  3000      -2     14\n",
      " Epoch  Reward  Steps\n",
      "  4000     -15     18\n",
      " Epoch  Reward  Steps\n",
      "  5000      11     10\n",
      " Epoch  Reward  Steps\n",
      "  6000     -19     22\n",
      " Epoch  Reward  Steps\n",
      "  7000       5     16\n",
      " Epoch  Reward  Steps\n",
      "  8000      -5     17\n",
      " Epoch  Reward  Steps\n",
      "  9000       3     18\n",
      " Epoch  Reward  Steps\n",
      " 10000      10     11\n"
     ]
    }
   ],
   "source": [
    "for index in range(0, len(df_10000_epochs), 1000):\n",
    "    row = df_10000_epochs.iloc[index]\n",
    "    data = pd.DataFrame([row], columns=[\"Epoch\", \"Reward\", \"Steps\"])\n",
    "    print(data.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "446a8b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adffe5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(env, epochs, discount_factor):\n",
    "    observation_space_size = env.observation_space.n\n",
    "    action_space_size = env.action_space.n\n",
    "    \n",
    "    q_table = np.zeros((observation_space_size, action_space_size))\n",
    "    \n",
    "    learning_rate = 0.1\n",
    "    exploration = 0.2\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for episode in range(epochs):\n",
    "        state = env.reset()\n",
    "        total_reward = 0\n",
    "        total_steps = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            if np.random.uniform(0, 1) < exploration:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                action = np.argmax(q_table[state, :])\n",
    "            \n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            q_table[state, action] = (1 - learning_rate) * q_table[state, action] + learning_rate * (reward + discount_factor * np.max(q_table[next_state, :]))\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            total_steps += 1\n",
    "        \n",
    "        results.append([episode, total_reward, total_steps, q_table])\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_agent(env, q_table, episodes):\n",
    "    total_rewards = []\n",
    "    total_steps = []\n",
    "    \n",
    "    for _ in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        episode_steps = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action = np.argmax(q_table[state, :])\n",
    "            state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            episode_steps += 1\n",
    "        \n",
    "        total_rewards.append(episode_reward)\n",
    "        total_steps.append(episode_steps)\n",
    "    \n",
    "    avg_reward = np.mean(total_rewards)\n",
    "    avg_steps = np.mean(total_steps)\n",
    "    \n",
    "    return avg_reward, avg_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ac9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Taxi-v3')\n",
    "epochs = 10000\n",
    "discount_factors = [0.3, 0.5, 0.9]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd11ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for discount_factor in discount_factors:\n",
    "    training_results = train_and_evaluate(env, epochs, discount_factor)\n",
    "    final_q_table = training_results[-1][3]  # Retrieve the final Q-Table after training\n",
    "    avg_reward, avg_steps = evaluate_agent(env, final_q_table, episodes=10)\n",
    "    results.append([discount_factor, avg_reward, avg_steps])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"Discount Factor\", \"Average Reward\", \"Average Steps\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fc6564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Discount Factor</th>\n",
       "      <th>Average Reward</th>\n",
       "      <th>Average Steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Discount Factor  Average Reward  Average Steps\n",
       "0              0.3           -33.2           50.0\n",
       "1              0.5             7.5           13.5\n",
       "2              0.9             9.5           11.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
